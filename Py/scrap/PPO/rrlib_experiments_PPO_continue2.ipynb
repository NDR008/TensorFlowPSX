{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Gym Environment\n",
    "\n",
    "```py\n",
    "my_config[\"interface\"] = MyGranTurismoRTGYM\n",
    "my_config[\"time_step_duration\"] = 0.05 # when to give up\n",
    "my_config[\"start_obs_capture\"] = 0.05 # when to capture \n",
    "my_config[\"time_step_timeout_factor\"] = 1.0 # how late is OK\n",
    "my_config[\"act_buf_len\"] = 3 # how many past actions\n",
    "my_config[\"reset_act_buf\"] = True # resect action buffer on reset\n",
    "my_config[\"benchmark\"] = True\n",
    "my_config[\"benchmark_polyak\"] = 0.2\n",
    "```\n",
    "\n",
    "This section needs to be setup for any method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from myRTClass import MyGranTurismoRTGYM, DEFAULT_CONFIG_DICT\n",
    "import gymnasium\n",
    "\n",
    "my_config = DEFAULT_CONFIG_DICT\n",
    "my_config[\"interface\"] = MyGranTurismoRTGYM\n",
    "my_config[\"time_step_duration\"] = 0.05\n",
    "my_config[\"start_obs_capture\"] = 0.05\n",
    "my_config[\"time_step_timeout_factor\"] = 1.0\n",
    "my_config[\"ep_max_length\"] = 2048\n",
    "my_config[\"act_buf_len\"] = 3\n",
    "my_config[\"reset_act_buf\"] = False\n",
    "my_config[\"benchmark\"] = True\n",
    "my_config[\"benchmark_polyak\"] = 0.2\n",
    "\n",
    "my_config[\"interface_kwargs\"] = {\n",
    "  'debugFlag': False, # do not use render() while True\n",
    "  'img_hist_len': 3,\n",
    "  'modelMode': 3,\n",
    "  'agent' : 'PPO',\n",
    "  #  [42, 42, K], [84, 84, K], [10, 10, K], [240, 320, K] and  [480, 640, K]\n",
    "  'imageWidth' : 42, # there is a default Cov layer for PPO with 240 x 320\n",
    "  'imageHeight' : 42,\n",
    "  'trackChoice' : 1, # 1 is High Speed Ring, # 2 is 0-400m\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    env = gymnasium.make(\"real-time-gym-v1\", config=env_config)\n",
    "    return env  # return an env instance\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"gt-rtgym-env-v1\", lambda config: env_creator(my_config)) # better way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the environment in a way that RLlib is happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 19:32:44,887\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m GT Real Time instantiated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m GT AI Server instantiated for rtgym\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m starting up on localhost port 9999\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m Waiting for a connection\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m Connection from ('127.0.0.1', 60493)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 19:33:53,752\tINFO trainable.py:172 -- Trainable.setup took 71.236 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-05-15 19:33:53,753\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "algo = Algorithm.from_checkpoint(\"C:/Users/nadir/ray_results/PPO/PPO_gt-rtgym-env-v1_2023-05-15_00-01-28t1hjvtdx/checkpoint_001591\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m reset triggered\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m reload save for track : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m c:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\rtgym\\envs\\real_time_env.py:376: UserWarning: Time-step timed out. Elapsed since last time-step: 0.5333819000005775\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15868)\u001b[0m   warnings.warn(f\"Time-step timed out. Elapsed since last time-step: {now - self.__t_end}\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mj:\\git\\TensorFlowPSX\\Py\\rrlib_experiments_PPO_continue.ipynb Cell 6\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlib_experiments_PPO_continue.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m N \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlib_experiments_PPO_continue.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlib_experiments_PPO_continue.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     result \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlib_experiments_PPO_continue.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoop: \u001b[39m\u001b[39m\"\u001b[39m, n)\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlib_experiments_PPO_continue.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:365\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    364\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 365\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    366\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    367\u001b[0m     skipped \u001b[39m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:782\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    774\u001b[0m     (\n\u001b[0;32m    775\u001b[0m         results,\n\u001b[0;32m    776\u001b[0m         train_iter_ctx,\n\u001b[0;32m    777\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[0;32m    778\u001b[0m \u001b[39m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 782\u001b[0m     results, train_iter_ctx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_training_iteration()\n\u001b[0;32m    784\u001b[0m \u001b[39m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[39mif\u001b[39;00m evaluate_this_iter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2713\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2711\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[0;32m   2712\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_disable_execution_plan_api:\n\u001b[1;32m-> 2713\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step()\n\u001b[0;32m   2714\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2715\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\algorithms\\ppo\\ppo.py:358\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     train_batch \u001b[39m=\u001b[39m synchronous_parallel_sample(\n\u001b[0;32m    354\u001b[0m         worker_set\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers,\n\u001b[0;32m    355\u001b[0m         max_agent_steps\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mtrain_batch_size,\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m     train_batch \u001b[39m=\u001b[39m synchronous_parallel_sample(\n\u001b[0;32m    359\u001b[0m         worker_set\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkers, max_env_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mtrain_batch_size\n\u001b[0;32m    360\u001b[0m     )\n\u001b[0;32m    361\u001b[0m train_batch \u001b[39m=\u001b[39m train_batch\u001b[39m.\u001b[39mas_multi_agent()\n\u001b[0;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_batch\u001b[39m.\u001b[39magent_steps()\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py:85\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[1;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[0;32m     82\u001b[0m     sample_batches \u001b[39m=\u001b[39m [worker_set\u001b[39m.\u001b[39mlocal_worker()\u001b[39m.\u001b[39msample()]\n\u001b[0;32m     83\u001b[0m \u001b[39m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     sample_batches \u001b[39m=\u001b[39m worker_set\u001b[39m.\u001b[39;49mforeach_worker(\n\u001b[0;32m     86\u001b[0m         \u001b[39mlambda\u001b[39;49;00m w: w\u001b[39m.\u001b[39;49msample(), local_worker\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, healthy_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m worker_set\u001b[39m.\u001b[39mnum_healthy_remote_workers() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     89\u001b[0m         \u001b[39m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[0;32m     90\u001b[0m         \u001b[39m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:692\u001b[0m, in \u001b[0;36mWorkerSet.foreach_worker\u001b[1;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[39mif\u001b[39;00m local_worker \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_worker() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m     local_result \u001b[39m=\u001b[39m [func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_worker())]\n\u001b[1;32m--> 692\u001b[0m remote_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__worker_manager\u001b[39m.\u001b[39;49mforeach_actor(\n\u001b[0;32m    693\u001b[0m     func,\n\u001b[0;32m    694\u001b[0m     healthy_only\u001b[39m=\u001b[39;49mhealthy_only,\n\u001b[0;32m    695\u001b[0m     remote_actor_ids\u001b[39m=\u001b[39;49mremote_worker_ids,\n\u001b[0;32m    696\u001b[0m     timeout_seconds\u001b[39m=\u001b[39;49mtimeout_seconds,\n\u001b[0;32m    697\u001b[0m     return_obj_refs\u001b[39m=\u001b[39;49mreturn_obj_refs,\n\u001b[0;32m    698\u001b[0m     mark_healthy\u001b[39m=\u001b[39;49mmark_healthy,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    701\u001b[0m handle_remote_call_result_errors(remote_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_worker_failures)\n\u001b[0;32m    703\u001b[0m \u001b[39m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:588\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[1;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    579\u001b[0m     func, remote_actor_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filter_func_and_remote_actor_id_by_state(\n\u001b[0;32m    580\u001b[0m         func, remote_actor_ids\n\u001b[0;32m    581\u001b[0m     )\n\u001b[0;32m    583\u001b[0m remote_calls \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_actors(\n\u001b[0;32m    584\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m    585\u001b[0m     remote_actor_ids\u001b[39m=\u001b[39mremote_actor_ids,\n\u001b[0;32m    586\u001b[0m )\n\u001b[1;32m--> 588\u001b[0m _, remote_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__fetch_result(\n\u001b[0;32m    589\u001b[0m     remote_actor_ids\u001b[39m=\u001b[39;49mremote_actor_ids,\n\u001b[0;32m    590\u001b[0m     remote_calls\u001b[39m=\u001b[39;49mremote_calls,\n\u001b[0;32m    591\u001b[0m     timeout_seconds\u001b[39m=\u001b[39;49mtimeout_seconds,\n\u001b[0;32m    592\u001b[0m     return_obj_refs\u001b[39m=\u001b[39;49mreturn_obj_refs,\n\u001b[0;32m    593\u001b[0m     mark_healthy\u001b[39m=\u001b[39;49mmark_healthy,\n\u001b[0;32m    594\u001b[0m )\n\u001b[0;32m    596\u001b[0m \u001b[39mreturn\u001b[39;00m remote_results\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:457\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.__fetch_result\u001b[1;34m(self, remote_actor_ids, remote_calls, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[39m# Notice that we do not return the refs to any unfinished calls to the\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# user, since it is not safe to handle such remote actor calls outside the\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# context of this actor manager. These requests are simply dropped.\u001b[39;00m\n\u001b[0;32m    456\u001b[0m timeout \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(timeout_seconds) \u001b[39mif\u001b[39;00m timeout_seconds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m ready, _ \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mwait(\n\u001b[0;32m    458\u001b[0m     remote_calls,\n\u001b[0;32m    459\u001b[0m     num_returns\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(remote_calls),\n\u001b[0;32m    460\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    461\u001b[0m     \u001b[39m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[0;32m    462\u001b[0m     fetch_local\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m return_obj_refs,\n\u001b[0;32m    463\u001b[0m )\n\u001b[0;32m    465\u001b[0m \u001b[39m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m remote_results \u001b[39m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTAI2\\lib\\site-packages\\ray\\_private\\worker.py:2578\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   2576\u001b[0m timeout \u001b[39m=\u001b[39m timeout \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m6\u001b[39m\n\u001b[0;32m   2577\u001b[0m timeout_milliseconds \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m-> 2578\u001b[0m ready_ids, remaining_ids \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mwait(\n\u001b[0;32m   2579\u001b[0m     object_refs,\n\u001b[0;32m   2580\u001b[0m     num_returns,\n\u001b[0;32m   2581\u001b[0m     timeout_milliseconds,\n\u001b[0;32m   2582\u001b[0m     worker\u001b[39m.\u001b[39;49mcurrent_task_id,\n\u001b[0;32m   2583\u001b[0m     fetch_local,\n\u001b[0;32m   2584\u001b[0m )\n\u001b[0;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:1833\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:199\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "\n",
    "for n in range(N):\n",
    "    result = algo.train()\n",
    "    print(\"Loop: \", n)\n",
    "    if n % 10 == 0:\n",
    "        print(\"Saved\", n)\n",
    "        algo.save()\n",
    "        \n",
    "algo.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTAI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
