{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial AI Agent Impala w CNN (working) MR2 HS Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myRTClass import MyGranTurismoRTGYM, DEFAULT_CONFIG_DICT\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from time import sleep\n",
    "\n",
    "my_config = DEFAULT_CONFIG_DICT\n",
    "my_config[\"interface\"] = MyGranTurismoRTGYM\n",
    "my_config[\"time_step_duration\"] = 0.1\n",
    "my_config[\"start_obs_capture\"] = 0.1\n",
    "my_config[\"time_step_timeout_factor\"] = 4.0\n",
    "#my_config[\"ep_max_length\"] = 200\n",
    "my_config[\"act_buf_len\"] = 4\n",
    "my_config[\"reset_act_buf\"] = False\n",
    "my_config[\"benchmark\"] = False\n",
    "my_config[\"benchmark_polyak\"] = 0.2\n",
    "\n",
    "my_config[\"interface_kwargs\"] = {\n",
    "  'debugFlag': False, # do not use render() while True\n",
    "  'discreteAccel' : True,\n",
    "  'accelAndBrake' : False,\n",
    "  'discSteer' : True,\n",
    "  'contAccelOnly' : False,\n",
    "  'discAccelOnly' : False,\n",
    "  'modelMode': 1,\n",
    "  'agent' : 'APPO',\n",
    "  #  [42, 42, K], [84, 84, K], [10, 10, K], [240, 320, K] and  [480, 640, K]\n",
    "  'imageWidth' : 42, # there is a default Cov layer for APPO with 240 x 320\n",
    "  'imageHeight' : 42,\n",
    "  'trackChoice' : 1, # 1 is High Speed Ring, 2 is 0-400m, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    env = gymnasium.make(\"real-time-gym-v1\", config=env_config)\n",
    "    return env  # return an env instance\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"gt-rtgym-env-v1\", lambda config: env_creator(my_config)) # better way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.impala.impala import ImpalaConfig\n",
    "config = (\n",
    "    ImpalaConfig()\n",
    "    .resources(\n",
    "        num_gpus=1\n",
    "        )\n",
    "    .rollouts(\n",
    "        num_rollout_workers=1,\n",
    "        enable_connectors=True,\n",
    "        batch_mode=\"truncate_episodes\",\n",
    "        )\n",
    "    .framework(\n",
    "        framework=\"torch\",\n",
    "        )\n",
    "    .environment(\n",
    "        env=\"gt-rtgym-env-v1\",\n",
    "        disable_env_checking=True,\n",
    "        render_env=False,\n",
    "        )\n",
    "    .training(\n",
    "        #train_batch_size=128,\n",
    "        )\n",
    ")\n",
    "\n",
    "#APPOConfig.framework(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        try:\n",
    "            json.dumps(obj)\n",
    "        except TypeError:\n",
    "            return \"Not serializable object!\"\n",
    "\n",
    "        return obj\n",
    "\n",
    "config_dict = config.to_dict()\n",
    "\n",
    "print(json.dumps(config_dict, sort_keys=True, indent=4, cls=CustomEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.get_policy().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mj:\\git\\TensorFlowPSX\\Py\\rrlibIMPALA_cnn_MR2_HS_.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIMPALA_cnn_MR2_HS_.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m N \u001b[39m=\u001b[39m \u001b[39m50000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIMPALA_cnn_MR2_HS_.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIMPALA_cnn_MR2_HS_.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     result \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIMPALA_cnn_MR2_HS_.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoop: \u001b[39m\u001b[39m\"\u001b[39m, n)\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIMPALA_cnn_MR2_HS_.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:372\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    370\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    371\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 372\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    373\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    374\u001b[0m     skipped \u001b[39m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:853\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    845\u001b[0m     (\n\u001b[0;32m    846\u001b[0m         results,\n\u001b[0;32m    847\u001b[0m         train_iter_ctx,\n\u001b[0;32m    848\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[0;32m    849\u001b[0m \u001b[39m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[39m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[39m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 853\u001b[0m     results, train_iter_ctx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_training_iteration()\n\u001b[0;32m    855\u001b[0m \u001b[39m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39mif\u001b[39;00m evaluate_this_iter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2837\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[0;32m   2836\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_disable_execution_plan_api:\n\u001b[1;32m-> 2837\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step()\n\u001b[0;32m   2838\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2839\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala.py:697\u001b[0m, in \u001b[0;36mImpala.training_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m use_tree_aggregation \u001b[39m=\u001b[39m (\n\u001b[0;32m    691\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregator_actor_manager\n\u001b[0;32m    692\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregator_actor_manager\u001b[39m.\u001b[39mnum_healthy_actors() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    693\u001b[0m )\n\u001b[0;32m    695\u001b[0m \u001b[39m# Get sampled SampleBatches from our workers (by ray references if we use\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[39m# tree-aggregation).\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m unprocessed_sample_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_samples_from_workers(\n\u001b[0;32m    698\u001b[0m     return_object_refs\u001b[39m=\u001b[39;49muse_tree_aggregation,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    700\u001b[0m \u001b[39m# Tag workers that actually produced ready sample batches this iteration.\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[39m# Those workers will have to get updated at the end of the iteration.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m workers_that_need_updates \u001b[39m=\u001b[39m {\n\u001b[0;32m    703\u001b[0m     worker_id \u001b[39mfor\u001b[39;00m worker_id, _ \u001b[39min\u001b[39;00m unprocessed_sample_batches\n\u001b[0;32m    704\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala.py:907\u001b[0m, in \u001b[0;36mImpala.get_samples_from_workers\u001b[1;34m(self, return_object_refs)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mnum_healthy_remote_workers() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    900\u001b[0m     \u001b[39m# Perform asynchronous sampling on all (remote) rollout workers.\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mforeach_worker_async(\n\u001b[0;32m    902\u001b[0m         \u001b[39mlambda\u001b[39;00m worker: worker\u001b[39m.\u001b[39msample(),\n\u001b[0;32m    903\u001b[0m         healthy_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    904\u001b[0m     )\n\u001b[0;32m    905\u001b[0m     sample_batches: List[\n\u001b[0;32m    906\u001b[0m         Tuple[\u001b[39mint\u001b[39m, ObjectRef]\n\u001b[1;32m--> 907\u001b[0m     ] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkers\u001b[39m.\u001b[39;49mfetch_ready_async_reqs(\n\u001b[0;32m    908\u001b[0m         timeout_seconds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout_s_sampler_manager,\n\u001b[0;32m    909\u001b[0m         return_obj_refs\u001b[39m=\u001b[39;49mreturn_object_refs,\n\u001b[0;32m    910\u001b[0m     )\n\u001b[0;32m    911\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[0;32m    912\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mlocal_worker()\n\u001b[0;32m    913\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mlocal_worker()\u001b[39m.\u001b[39masync_env \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    914\u001b[0m ):\n\u001b[0;32m    915\u001b[0m     \u001b[39m# Sampling from the local worker\u001b[39;00m\n\u001b[0;32m    916\u001b[0m     sample_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mlocal_worker()\u001b[39m.\u001b[39msample()\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:782\u001b[0m, in \u001b[0;36mWorkerSet.fetch_ready_async_reqs\u001b[1;34m(self, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[39m@DeveloperAPI\u001b[39m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch_ready_async_reqs\u001b[39m(\n\u001b[0;32m    765\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m     mark_healthy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mint\u001b[39m, T]]:\n\u001b[0;32m    771\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get esults from outstanding asynchronous requests that are ready.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \n\u001b[0;32m    773\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39m        paired with the indices of the callee workers.\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     remote_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__worker_manager\u001b[39m.\u001b[39;49mfetch_ready_async_reqs(\n\u001b[0;32m    783\u001b[0m         timeout_seconds\u001b[39m=\u001b[39;49mtimeout_seconds,\n\u001b[0;32m    784\u001b[0m         return_obj_refs\u001b[39m=\u001b[39;49mreturn_obj_refs,\n\u001b[0;32m    785\u001b[0m         mark_healthy\u001b[39m=\u001b[39;49mmark_healthy,\n\u001b[0;32m    786\u001b[0m     )\n\u001b[0;32m    788\u001b[0m     handle_remote_call_result_errors(remote_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_worker_failures)\n\u001b[0;32m    790\u001b[0m     \u001b[39mreturn\u001b[39;00m [(r\u001b[39m.\u001b[39mactor_id, r\u001b[39m.\u001b[39mget()) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m remote_results\u001b[39m.\u001b[39mignore_errors()]\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:753\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.fetch_ready_async_reqs\u001b[1;34m(self, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[39m# Construct the list of in-flight requests filtered by tag.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m remote_calls, remote_actor_ids, valid_tags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__filter_calls_by_tag(tags)\n\u001b[1;32m--> 753\u001b[0m ready, remote_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__fetch_result(\n\u001b[0;32m    754\u001b[0m     remote_actor_ids\u001b[39m=\u001b[39;49mremote_actor_ids,\n\u001b[0;32m    755\u001b[0m     remote_calls\u001b[39m=\u001b[39;49mremote_calls,\n\u001b[0;32m    756\u001b[0m     tags\u001b[39m=\u001b[39;49mvalid_tags,\n\u001b[0;32m    757\u001b[0m     timeout_seconds\u001b[39m=\u001b[39;49mtimeout_seconds,\n\u001b[0;32m    758\u001b[0m     return_obj_refs\u001b[39m=\u001b[39;49mreturn_obj_refs,\n\u001b[0;32m    759\u001b[0m     mark_healthy\u001b[39m=\u001b[39;49mmark_healthy,\n\u001b[0;32m    760\u001b[0m )\n\u001b[0;32m    762\u001b[0m \u001b[39mfor\u001b[39;00m obj_ref, result \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ready, remote_results):\n\u001b[0;32m    763\u001b[0m     \u001b[39m# Decrease outstanding request on this actor by 1.\u001b[39;00m\n\u001b[0;32m    764\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__remote_actor_states[\n\u001b[0;32m    765\u001b[0m         result\u001b[39m.\u001b[39mactor_id\n\u001b[0;32m    766\u001b[0m     ]\u001b[39m.\u001b[39mnum_in_flight_async_requests \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:460\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.__fetch_result\u001b[1;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m remote_calls:\n\u001b[0;32m    458\u001b[0m     \u001b[39mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[1;32m--> 460\u001b[0m ready, _ \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mwait(\n\u001b[0;32m    461\u001b[0m     remote_calls,\n\u001b[0;32m    462\u001b[0m     num_returns\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(remote_calls),\n\u001b[0;32m    463\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    464\u001b[0m     \u001b[39m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[0;32m    465\u001b[0m     fetch_local\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m return_obj_refs,\n\u001b[0;32m    466\u001b[0m )\n\u001b[0;32m    468\u001b[0m \u001b[39m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m remote_results \u001b[39m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\_private\\auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     23\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.6.3_torch_tb\\lib\\site-packages\\ray\\_private\\worker.py:2732\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   2730\u001b[0m timeout \u001b[39m=\u001b[39m timeout \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m6\u001b[39m\n\u001b[0;32m   2731\u001b[0m timeout_milliseconds \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m-> 2732\u001b[0m ready_ids, remaining_ids \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mwait(\n\u001b[0;32m   2733\u001b[0m     object_refs,\n\u001b[0;32m   2734\u001b[0m     num_returns,\n\u001b[0;32m   2735\u001b[0m     timeout_milliseconds,\n\u001b[0;32m   2736\u001b[0m     worker\u001b[39m.\u001b[39;49mcurrent_task_id,\n\u001b[0;32m   2737\u001b[0m     fetch_local,\n\u001b[0;32m   2738\u001b[0m )\n\u001b[0;32m   2739\u001b[0m \u001b[39mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 50000\n",
    "\n",
    "for n in range(N):\n",
    "    result = algo.train()\n",
    "    print(\"Loop: \", n)\n",
    "    if n % 10 == 0:\n",
    "        print(\"Saved\", n)\n",
    "        algo.save()\n",
    "        \n",
    "algo.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTAI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
