{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial AI Agent PPO w/o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myRTClass import MyGranTurismoRTGYM, DEFAULT_CONFIG_DICT\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from time import sleep\n",
    "\n",
    "my_config = DEFAULT_CONFIG_DICT\n",
    "my_config[\"interface\"] = MyGranTurismoRTGYM\n",
    "my_config[\"time_step_duration\"] = 0.05\n",
    "my_config[\"start_obs_capture\"] = 0.05\n",
    "my_config[\"time_step_timeout_factor\"] = 1.0\n",
    "my_config[\"ep_max_length\"] = 900\n",
    "my_config[\"act_buf_len\"] = 4\n",
    "my_config[\"reset_act_buf\"] = True\n",
    "my_config[\"benchmark\"] = False\n",
    "my_config[\"benchmark_polyak\"] = 0.2\n",
    "\n",
    "my_config[\"interface_kwargs\"] = {\n",
    "  'debugFlag': False, # do not use render() while True\n",
    "  'discreteAccel' : True,\n",
    "  'accelAndBrake' : False,\n",
    "  'discSteer' : True,\n",
    "  'contAccelOnly' : False,\n",
    "  'discAccelOnly' : False,\n",
    "  'modelMode': 14,\n",
    "  #  [42, 42, K], [84, 84, K], [10, 10, K], [240, 320, K] and  [480, 640, K]\n",
    "  'imageWidth' : 42, # there is a default Cov layer for PPO with 240 x 320\n",
    "  'imageHeight' : 42,\n",
    "  'trackChoice' : 1, # 0 is HS, 1 is 400m\n",
    "  'carChoice' : 0, # 0 is MR2, 1 is Supra, 2 is Civic\n",
    "  'rewardMode' : \"simplex\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    env = gymnasium.make(\"real-time-gym-v1\", config=env_config)\n",
    "    return env  # return an env instance\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"gt-rtgym-env-v1\", lambda config: env_creator(my_config)) # better way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 12:21:15,588\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.4.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.9', ray_version='2.4.0', ray_commit='4479f66d4db967d3c9dd0af2572061276ba926ba', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:63328', 'raylet_socket_name': 'tcp://127.0.0.1:60916', 'webui_url': '127.0.0.1:8265', 'session_dir': 'C:\\\\Users\\\\nadir\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2023-10-15_12-21-12_961212_7736', 'metrics_export_port': 65215, 'gcs_address': '127.0.0.1:64417', 'address': '127.0.0.1:64417', 'dashboard_agent_listen_port': 52365, 'node_id': '56659a8eb621efcd5a151946d7759641833bfe10c85d972b22e81624'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .resources(\n",
    "        num_gpus=1\n",
    "        )\n",
    "    .rollouts(\n",
    "        num_rollout_workers=1,\n",
    "        enable_connectors=True,\n",
    "        batch_mode=\"truncate_episodes\",\n",
    "        #batch_mode=\"completed_episodes\",\n",
    "        )\n",
    "    .framework(\n",
    "        framework=\"torch\",\n",
    "        )\n",
    "    .environment(\n",
    "        env=\"gt-rtgym-env-v1\",\n",
    "        disable_env_checking=True,\n",
    "        render_env=False,\n",
    "        )\n",
    "    .training(\n",
    "        train_batch_size=600,\n",
    "        lr=0,\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# class CustomEncoder(json.JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         try:\n",
    "#             json.dumps(obj)\n",
    "#         except TypeError:\n",
    "#             return \"Not serializable object!\"\n",
    "\n",
    "#         return obj\n",
    "\n",
    "# config_dict = config.to_dict()\n",
    "\n",
    "# print(json.dumps(config_dict, sort_keys=True, indent=4, cls=CustomEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.rllib.policy.policy import Policy\n",
    "\n",
    "# # Use the `from_checkpoint` utility of the Policy class:\n",
    "# my_restored_policy = Policy.from_checkpoint(\"C:/Users/nadir/ray_results/PPO_gt-rtgym-env-v1_2023-10-14_22-11-44ayp9l_kd/checkpoint_000881/policies/default_policy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 12:21:21,412\tWARNING checkpoints.py:109 -- No `rllib_checkpoint.json` file found in checkpoint directory C:/Users/nadir/ray_results/PPO_gt-rtgym-env-v1_2023-10-14_22-11-44ayp9l_kd/checkpoint_000881! Trying to extract checkpoint info from other files found in that dir.\n",
      "2023-10-15 12:21:21,460\tINFO algorithm.py:527 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m GT Real Time instantiated\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m GT AI Server instantiated for rtgym\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m starting up on localhost port 9999\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m Waiting for a connection\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m Connection from ('127.0.0.1', 59559)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m J:\\git\\TensorFlowPSX\\Py\\dragSpaced.csv\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4692)\u001b[0m Discrete Accel or Brake (cannot left foot) and Discrete Steering 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 12:21:36,698\tINFO trainable.py:172 -- Trainable.setup took 15.239 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "algo = Algorithm.from_checkpoint(\"C:/Users/nadir/ray_results/PPO_gt-rtgym-env-v1_2023-10-14_22-11-44ayp9l_kd/checkpoint_000881\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate w/o an evaluation worker set in the Trainer or w/o an env on the local worker!\nTry one of the following:\n1) Set `evaluation_interval` >= 0 to force creating a separate evaluation worker set.\n2) Set `create_env_on_driver=True` to force the local (non-eval) worker to have an environment to evaluate on.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mj:\\git\\TensorFlowPSX\\Py\\rrlibIPPO_MR2_Drag_inference.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIPPO_MR2_Drag_inference.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#result = algo.train() #single try with lr=0\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/j%3A/git/TensorFlowPSX/Py/rrlibIPPO_MR2_Drag_inference.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m algo\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\nadir\\anaconda3\\envs\\GTRay2.3.0\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:900\u001b[0m, in \u001b[0;36mAlgorithm.evaluate\u001b[1;34m(self, duration_fn)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_workers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mlocal_worker()\u001b[39m.\u001b[39minput_reader \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     ):\n\u001b[1;32m--> 900\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    901\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot evaluate w/o an evaluation worker set in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    902\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe Trainer or w/o an env on the local worker!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTry one of the following:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m1) Set \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`evaluation_interval` >= 0 to force creating a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mseparate evaluation worker set.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m2) Set \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`create_env_on_driver=True` to force the local \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    907\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(non-eval) worker to have an environment to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    908\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mevaluate on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         )\n\u001b[0;32m    911\u001b[0m     \u001b[39m# How many episodes/timesteps do we need to run?\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     \u001b[39m# In \"auto\" mode (only for parallel eval + training): Run as long\u001b[39;00m\n\u001b[0;32m    913\u001b[0m     \u001b[39m# as training lasts.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m     unit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mevaluation_duration_unit\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot evaluate w/o an evaluation worker set in the Trainer or w/o an env on the local worker!\nTry one of the following:\n1) Set `evaluation_interval` >= 0 to force creating a separate evaluation worker set.\n2) Set `create_env_on_driver=True` to force the local (non-eval) worker to have an environment to evaluate on."
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    result = algo.train() #single try with lr=0\n",
    "#algo.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTAI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
