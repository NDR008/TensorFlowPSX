{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point(x=-1486, y=280)\n",
      "Point(x=-1469, y=1070)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui as py\n",
    "import time\n",
    "for i in range(0,2):\n",
    "    time.sleep(5)\n",
    "    print(py.position())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mj:\\git\\screen_reading\\main.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=79'>80</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=81'>82</a>\u001b[0m         b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=84'>85</a>\u001b[0m screen_record()\n",
      "\u001b[1;32mj:\\git\\screen_reading\\main.ipynb Cell 2'\u001b[0m in \u001b[0;36mscreen_record\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=67'>68</a>\u001b[0m \u001b[39m# fps_avg = fps_avg + (1/(time.time()-last_time)) / b\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=68'>69</a>\u001b[0m \u001b[39m# printscreen = np.array(ImageGrab.grab(bbox=(455, 200, 975, 589)))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=69'>70</a>\u001b[0m printscreen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(ImageGrab\u001b[39m.\u001b[39mgrab(bbox\u001b[39m=\u001b[39m(\u001b[39m200\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m1700\u001b[39m, \u001b[39m1100\u001b[39m)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=70'>71</a>\u001b[0m proScreen \u001b[39m=\u001b[39m procImage(printscreen)\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=71'>72</a>\u001b[0m \u001b[39m# print('loop took {} seconds'.format(1/(time.time()-last_time)))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=72'>73</a>\u001b[0m \u001b[39m# last_time = time.time()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=73'>74</a>\u001b[0m \u001b[39m# cv2.imshow('window', cv2.cvtColor(printscreen, cv2.COLOR_BGR2RGB))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=74'>75</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mwindow\u001b[39m\u001b[39m'\u001b[39m, proScreen)\n",
      "\u001b[1;32mj:\\git\\screen_reading\\main.ipynb Cell 2'\u001b[0m in \u001b[0;36mprocImage\u001b[1;34m(originalImage)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=20'>21</a>\u001b[0m \u001b[39m# Sobel Edge Detection on the X axis\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=21'>22</a>\u001b[0m \u001b[39m# sobelx = cv2.Sobel(src=processed_img, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=22'>23</a>\u001b[0m \u001b[39m# sobely = cv2.Sobel(src=processed_img, ddepth=cv2.CV_64F, dx=0,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=23'>24</a>\u001b[0m \u001b[39m#                dy=1, ksize=5)  # Sobel Edge Detection on the Y axis\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=24'>25</a>\u001b[0m \u001b[39m# sobelxy = cv2.Sobel(src=processed_img, ddepth=cv2.CV_64F,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=25'>26</a>\u001b[0m \u001b[39m#                 dx=1, dy=1, ksize=11)  # Combined X\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=27'>28</a>\u001b[0m lines \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mHoughLinesP(processed_img, \u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m180\u001b[39m, \u001b[39m180\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=28'>29</a>\u001b[0m draw_lines(processed_img, lines)\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m processed_img\n",
      "\u001b[1;32mj:\\git\\screen_reading\\main.ipynb Cell 2'\u001b[0m in \u001b[0;36mdraw_lines\u001b[1;34m(image, lines)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_lines\u001b[39m(image, lines):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=10'>11</a>\u001b[0m         coords \u001b[39m=\u001b[39m line[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/git/screen_reading/main.ipynb#ch0000000?line=11'>12</a>\u001b[0m         cv2\u001b[39m.\u001b[39mline(image, (coords[\u001b[39m0\u001b[39m], coords[\u001b[39m1\u001b[39m]), (coords[\u001b[39m2\u001b[39m], coords[\u001b[39m3\u001b[39m]), [\u001b[39m255\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m], \u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Might redo in gl shader\n",
    "# https: // towardsdatascience.com/how-i-learned-lane-detection-using-asphalt-8-airborne-bae4d0982134\n",
    "\n",
    "def draw_lines(image, lines):\n",
    "    for line in lines:\n",
    "        coords = line[0]\n",
    "        cv2.line(image, (coords[0], coords[1]), (coords[2], coords[3]), [255,100,100], 3)\n",
    "\n",
    "\n",
    "def procImage(originalImage):\n",
    "    # convert to gray\n",
    "    processed_img = cv2.cvtColor(originalImage, cv2.COLOR_BGR2GRAY)\n",
    "    processed_img = cv2.GaussianBlur(processed_img, (5, 5), 0)\n",
    "    # edge detectionq\n",
    "    processed_img = cv2.Canny(processed_img, threshold1=50, threshold2=250)\n",
    "    # Sobel Edge Detection on the X axis\n",
    "    # sobelx = cv2.Sobel(src=processed_img, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5)\n",
    "    # sobely = cv2.Sobel(src=processed_img, ddepth=cv2.CV_64F, dx=0,\n",
    "    #                dy=1, ksize=5)  # Sobel Edge Detection on the Y axis\n",
    "    # sobelxy = cv2.Sobel(src=processed_img, ddepth=cv2.CV_64F,\n",
    "    #                 dx=1, dy=1, ksize=11)  # Combined X\n",
    "    \n",
    "    lines = cv2.HoughLinesP(processed_img, 1, np.pi/180, 180, 10, 4)\n",
    "    draw_lines(processed_img, lines)\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "\n",
    "def overlay_lines(image, lines):\n",
    "    try:\n",
    "        for line in lines:\n",
    "            coordinates = line[0]\n",
    "            cv2.line(image, (coordinates[0], coordinates[1]),\n",
    "                     (coordinates[2], coordinates[3]), [1, 0.5, 0.5], 10)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def edgeprocessed(image, lower):\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edgeprocessed_img = cv2.Canny(gray_image, threshold1=100,\n",
    "                                  threshold2=200+lower)\n",
    "\n",
    "    edgeprocessed_img = cv2.GaussianBlur(edgeprocessed_img, (3, 3), 2)\n",
    "\n",
    "    return edgeprocessed_img\n",
    "\n",
    "# canny image processing for detecting edges\n",
    "## https://www.youtube.com/watch?v=ks4MPfMq8aQ&list=PLQVvvaa0QuDeETZEOy4VdocT7TOjfSA8a&index=2\n",
    "\n",
    "\n",
    "def screen_record():\n",
    "    last_time = time.time()\n",
    "    b = 1\n",
    "    fps_avg = 0\n",
    "    last_time = .0000001\n",
    "    lower = 10\n",
    "    while(True):\n",
    "        if b % 10000 == 0:\n",
    "            lower = lower + 10\n",
    "        # fps_avg = fps_avg + (1/(time.time()-last_time)) / b\n",
    "        # printscreen = np.array(ImageGrab.grab(bbox=(455, 200, 975, 589)))\n",
    "        printscreen = np.array(ImageGrab.grab(bbox=(200, 200, 1700, 1100)))\n",
    "        proScreen = procImage(printscreen)\n",
    "        # print('loop took {} seconds'.format(1/(time.time()-last_time)))\n",
    "        # last_time = time.time()\n",
    "        # cv2.imshow('window', cv2.cvtColor(printscreen, cv2.COLOR_BGR2RGB))\n",
    "        cv2.imshow('window', proScreen)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            print(b)\n",
    "            break\n",
    "\n",
    "        b = b + 1\n",
    "\n",
    "\n",
    "screen_record()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "406c150ef94c8a446f992d8668df7c7bae7e919ad22ae444febc63d44d2dc557"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gym1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
